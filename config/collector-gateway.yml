# we can have many recievers (list)
receivers:
  otlp:
  # defining porotocl we are listing to 
    protocols: 
    # http protocl 
      http:
        # listening to port 4318 (defaut port for OTEL collector)
        # this endpoint has to correspond to the ports lsited in the docker file
        endpoint: 0.0.0.0:4319
      grpc: 
        endpoint: 0.0.0.0:4320

# processors processes your telemtry before sending it off
processors: 
  # processor 1: batch - doing it in batches every 1 second 
  batch:
    timeout: 1s
  # processor 2: resource - alter incoming data by adding attribute 
  resource:
    attributes: 
      - key: test.key
        value: "test-value"
        action: insert

# exports the OTEL data to vendors or your backend of choice 
exporters:

  otelphttp:
    endpoint: "http://localhost:3000/telemetry"
    headers: 
      Content-Type: "application/json"
    insecure: true
  # indicate metrics to be exported to Promoethus
  prometheus:
    # this endpoint has to correspond to the ports lsited in the docker file
    endpoint: "0.0.0.0:8889"
    # configuration on data
    send_timestamps: true
    namespace: promexample
    const_labels:
      label1: value

  # this is for logging everything to the console
  logging:
    loglevel: info

  # tracing exporter 
  jaeger:
    # this endpoint has to correspond to the ports lsited in the docker file
    endpoint: jaeger:14250
    # configuration on data
    # no encryption
    insecure: true

# additonal plugins or extensions for the collector
extensions: 
  # checking everyhting works as expected
  health_check:
  # gives us access to performance data
  pprof:
    endpoint: :1888
  # debugging data
  zpages: 
    endpoint: :55679

# define how all the tools and processors in the collector work together
service:
  extensions: [pprof, zpages, health_check]
  # define steps for incoming traces and metric etc. to be handled
  pipelines:
    # trace specifc
    traces:
      # where it is being recieved
      receivers: [otlp]
      # how it is being processed
      processors: [batch, resource]
      # where it is being sent to
      exporters: [logging, jaeger, otelphttp]
    # metrics specifc
    metrics:
      recievers: [otlp]
      # how it is being processed
      processors: [batch]
      exporters: [logging, prometheus, otelphttp]



